{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script type=\"text/javascript\" src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default\"></script>\n",
    "# 朴素贝叶斯模型\n",
    "\n",
    "**先验概率**：$P(H | X)$ 先得到结果$X$来推算到的$H$的概率\n",
    "\n",
    "**后验概率**：$P(H)$直接对$H$求概率\n",
    "\n",
    "**贝叶斯公式**：$$ P(H|X) = \\frac{P(X|H)P(H)}{P(X)} $$\n",
    "\n",
    "## 朴素贝叶斯分类\n",
    "**步骤**：\n",
    "\n",
    "1. 设$D$是训练元组和它们相关联的类标号集合。每个元组用一个n维属性向量$X = {x_1,x_2, \\cdots, x_n}$表示，描述$n$个属性$A_1,A_2, \\cdots, A_n$对元组的$n$个测量。\n",
    "2. 假设有$m$个类$C_1,C_2, \\cdots, C_n$。给定元组$X$，分类器将预测$X$属于最高后验概率的类。也就是说，朴素贝叶斯分类法预测$X$属于类$C_i$，当且仅当$$P(C_i|X) > P(C_j|X)~~~1\\leq j\\leq m,~~j\\ne i$$，最大化$P(C_i|X)$。$P(C_i|X)$是最大的类$C_i$称为最大后验假设。根据贝叶斯定理：\n",
    "$$P(C_i|X) = \\frac{P(X|C_i)P(C_i)}{P(X)}$$\n",
    "3. 由于$P(X)$对所有类为常数，只需要$P(X|C_i)P(C_i)$最大即可。如果类的先验概率未知，则通常假定这些类是等概率的，即$P(C_i)=P(C_2)=\\cdots =P(C_m)$，并对$P(X|C_i)$最大化。否则，最大化$P(X|C_i)P(C_i)$。类先验概率可以使用$P(C_i) = \\frac{|C_{i,D}|}{|D|}$估计，其中$|C_{i,D}|$是训练元组数。\n",
    "4. 给定具有许多属性的数据集，计算$P(X|C_i)$的开销可能非常大。为了降低计算$P(X|C_i)$的开销，假定所有概率满足条件独立，即：\n",
    "$$ P(X|C_i) = P(x_1|C_i)P(x_2|C_i)\\cdots P(x_n|C_i) $$\n",
    "    * 若$A_k$是分类属性，则$P(x_k|C_i)$计算方法为：$D$中属性$A_k$的值为$x_k$的$C_i$类的元组数除以$D$中$C_i$类的元组数$|C_{i,D}|$。\n",
    "    * 若$A_k$是连续属性，假定属性服从均值为$\\mu$，标准差为$\\sigma$的高斯分布，则：\n",
    "    $$ g(x,\\mu,\\sigma) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{- \\frac{(x-\\mu)^2}{2\\sigma^2}}~~~~P(x_k|C_i) = g(x_k,u_{c_i},\\sigma_{c_i})$$\n",
    "    \n",
    "朴素贝叶斯的条件独立性很难再实际中满足，故效果往往不是特别好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iris花分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, naive_bayes, metrics,ensemble\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "0.13095238095238096\n",
      "CategoricalNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.8982456140350877\n",
      "ComplementNB(alpha=1.0, class_prior=None, fit_prior=True, norm=False)\n",
      "0.5166666666666666\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "1.0\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.5166666666666666\n"
     ]
    }
   ],
   "source": [
    "data_iris = datasets.load_iris()\n",
    "data = data_iris['data']\n",
    "label = data_iris['target']\n",
    "X_train,X_val,Y_train,Y_val = train_test_split(data,label, test_size = 0.3, random_state = 0)\n",
    "#-------------------------BernoulliNB\n",
    "bay_model = naive_bayes.BernoulliNB()\n",
    "bay_model.fit(X_train,Y_train)\n",
    "\n",
    "preds = bay_model.predict(X_val)\n",
    "print(bay_model)\n",
    "print(metrics.f1_score(Y_val,preds,average = 'macro'))\n",
    "\n",
    "#-------------------------CategoricalNB\n",
    "bay_model = naive_bayes.CategoricalNB()\n",
    "bay_model.fit(X_train,Y_train)\n",
    "\n",
    "preds = bay_model.predict(X_val)\n",
    "print(bay_model)\n",
    "print(metrics.f1_score(Y_val,preds,average = 'macro'))\n",
    "\n",
    "#-------------------------ComplementNB\n",
    "bay_model = naive_bayes.ComplementNB()\n",
    "bay_model.fit(X_train,Y_train)\n",
    "\n",
    "preds = bay_model.predict(X_val)\n",
    "print(bay_model)\n",
    "print(metrics.f1_score(Y_val,preds,average = 'macro'))\n",
    "\n",
    "#-------------------------GaussianNB\n",
    "bay_model = naive_bayes.GaussianNB()\n",
    "bay_model.fit(X_train,Y_train)\n",
    "\n",
    "preds = bay_model.predict(X_val)\n",
    "print(bay_model)\n",
    "print(metrics.f1_score(Y_val,preds,average = 'macro'))\n",
    "\n",
    "#-------------------------MultinomialNB\n",
    "bay_model = naive_bayes.MultinomialNB()\n",
    "bay_model.fit(X_train,Y_train)\n",
    "\n",
    "preds = bay_model.predict(X_val)\n",
    "print(bay_model)\n",
    "print(metrics.f1_score(Y_val,preds,average = 'macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 词分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "0.706918505942275\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.89      0.51      0.65       201\n",
      "           comp.graphics       0.81      0.62      0.70       250\n",
      " comp.os.ms-windows.misc       0.80      0.03      0.06       248\n",
      "comp.sys.ibm.pc.hardware       0.40      0.90      0.55       240\n",
      "   comp.sys.mac.hardware       0.52      0.84      0.64       242\n",
      "          comp.windows.x       0.97      0.65      0.78       263\n",
      "            misc.forsale       0.40      0.91      0.55       257\n",
      "               rec.autos       0.54      0.85      0.66       238\n",
      "         rec.motorcycles       0.97      0.85      0.91       276\n",
      "      rec.sport.baseball       0.90      0.86      0.88       251\n",
      "        rec.sport.hockey       0.97      0.92      0.94       233\n",
      "               sci.crypt       0.89      0.83      0.86       238\n",
      "         sci.electronics       0.85      0.79      0.82       249\n",
      "                 sci.med       0.95      0.73      0.83       245\n",
      "               sci.space       0.89      0.84      0.86       221\n",
      "  soc.religion.christian       0.63      0.81      0.70       232\n",
      "      talk.politics.guns       0.87      0.74      0.80       251\n",
      "   talk.politics.mideast       0.95      0.71      0.81       231\n",
      "      talk.politics.misc       0.95      0.40      0.57       188\n",
      "      talk.religion.misc       1.00      0.01      0.02       158\n",
      "\n",
      "                accuracy                           0.71      4712\n",
      "               macro avg       0.81      0.69      0.68      4712\n",
      "            weighted avg       0.80      0.71      0.69      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups  # 从sklearn.datasets里导入新闻数据抓取器 fetch_20newsgroups\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # 从sklearn.feature_extraction.text里导入文本特征向量化模块\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#1.数据获取\n",
    "news = fetch_20newsgroups(subset='all')\n",
    "\n",
    "#2.数据预处理：训练集和测试集分割，文本特征向量化\n",
    "X_train,X_val,y_train,y_val = train_test_split(news.data,news.target,test_size=0.25,random_state=33) # 随机采样25%的数据样本作为测试集\n",
    "\n",
    "#文本特征向量化\n",
    "vec = CountVectorizer()\n",
    "X_train = vec.fit_transform(X_train)\n",
    "X_val = vec.transform(X_val)\n",
    "\n",
    "bay_model = naive_bayes.BernoulliNB()  \n",
    "bay_model.fit(X_train,y_train)    \n",
    "y_predict = bay_model.predict(X_val)\n",
    "\n",
    "print(bay_model)\n",
    "print(bay_model.score(X_val,y_val))\n",
    "print(classification_report(y_val, y_predict, target_names = news.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComplementNB(alpha=1.0, class_prior=None, fit_prior=True, norm=False)\n",
      "0.8994057724957555\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.88      0.87      0.87       201\n",
      "           comp.graphics       0.80      0.86      0.83       250\n",
      " comp.os.ms-windows.misc       0.91      0.70      0.79       248\n",
      "comp.sys.ibm.pc.hardware       0.74      0.88      0.80       240\n",
      "   comp.sys.mac.hardware       0.96      0.87      0.91       242\n",
      "          comp.windows.x       0.89      0.91      0.90       263\n",
      "            misc.forsale       0.88      0.76      0.81       257\n",
      "               rec.autos       0.93      0.95      0.94       238\n",
      "         rec.motorcycles       0.96      0.97      0.97       276\n",
      "      rec.sport.baseball       0.96      0.95      0.96       251\n",
      "        rec.sport.hockey       0.90      1.00      0.95       233\n",
      "               sci.crypt       0.94      0.99      0.96       238\n",
      "         sci.electronics       0.94      0.89      0.92       249\n",
      "                 sci.med       0.94      0.96      0.95       245\n",
      "               sci.space       0.91      0.96      0.93       221\n",
      "  soc.religion.christian       0.84      0.97      0.90       232\n",
      "      talk.politics.guns       0.92      0.97      0.94       251\n",
      "   talk.politics.mideast       0.92      1.00      0.96       231\n",
      "      talk.politics.misc       0.93      0.90      0.92       188\n",
      "      talk.religion.misc       0.91      0.53      0.67       158\n",
      "\n",
      "                accuracy                           0.90      4712\n",
      "               macro avg       0.90      0.89      0.89      4712\n",
      "            weighted avg       0.90      0.90      0.90      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bay_model = naive_bayes.ComplementNB()\n",
    "bay_model.fit(X_train,y_train)    \n",
    "y_predict = bay_model.predict(X_val)     \n",
    "\n",
    "print(bay_model)\n",
    "print(bay_model.score(X_val,y_val))\n",
    "print(classification_report(y_val, y_predict, target_names = news.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.8397707979626485\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.86      0.86      0.86       201\n",
      "           comp.graphics       0.59      0.86      0.70       250\n",
      " comp.os.ms-windows.misc       0.89      0.10      0.17       248\n",
      "comp.sys.ibm.pc.hardware       0.60      0.88      0.72       240\n",
      "   comp.sys.mac.hardware       0.93      0.78      0.85       242\n",
      "          comp.windows.x       0.82      0.84      0.83       263\n",
      "            misc.forsale       0.91      0.70      0.79       257\n",
      "               rec.autos       0.89      0.89      0.89       238\n",
      "         rec.motorcycles       0.98      0.92      0.95       276\n",
      "      rec.sport.baseball       0.98      0.91      0.95       251\n",
      "        rec.sport.hockey       0.93      0.99      0.96       233\n",
      "               sci.crypt       0.86      0.98      0.91       238\n",
      "         sci.electronics       0.85      0.88      0.86       249\n",
      "                 sci.med       0.92      0.94      0.93       245\n",
      "               sci.space       0.89      0.96      0.92       221\n",
      "  soc.religion.christian       0.78      0.96      0.86       232\n",
      "      talk.politics.guns       0.88      0.96      0.92       251\n",
      "   talk.politics.mideast       0.90      0.98      0.94       231\n",
      "      talk.politics.misc       0.79      0.89      0.84       188\n",
      "      talk.religion.misc       0.93      0.44      0.60       158\n",
      "\n",
      "                accuracy                           0.84      4712\n",
      "               macro avg       0.86      0.84      0.82      4712\n",
      "            weighted avg       0.86      0.84      0.82      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bay_model = naive_bayes.MultinomialNB()\n",
    "bay_model.fit(X_train,y_train)    \n",
    "y_predict = bay_model.predict(X_val)     \n",
    "\n",
    "print(bay_model)\n",
    "print(bay_model.score(X_val,y_val))\n",
    "print(classification_report(y_val, y_predict, target_names = news.target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
